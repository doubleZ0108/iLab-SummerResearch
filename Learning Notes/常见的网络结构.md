# 常见的网络结构

## 目录

- [LeNet -> 开山之作](#LeNet)
  * [基本架构](#LeNet基本架构)
  * [LeNet-5模型](#LeNet-5模型)
  * [LeNet的Keras实现](#LeNet的Keras实现)
- [AlexNet -> 王者归来](#AlexNet)
  * [优势](#AlexNet优势)
  * [AlexNet模型](#AlexNet模型)
  * [AlexNet的Keras实现](#AlexNet的Keras实现)
- [Googlenet -> 大浪推手](#Googlenet)
  * [优势](#Googlenet优势)
  * [Inception模型](#Inception模型)
  * [GoogLeNet的Keras实现](#GoogLeNet的Keras实现)
- [VGG -> 越走越深](#VGG)
  * [简介](#VGG简介)
  * [VGG-16网络结构](#VGG-16网络结构)
  * [VGG-16的Keras实现](#VGG-16的Keras实现)
- [Resent -> 里程碑式的创新](#Resent)
  * [优势](#Resent优势)
  * [残差单元](#残差单元)
  * [ResNet-50的Keras实现](#ResNet-50的Keras实现)

<a name="LeNet"></a>

## LeNet -> 开山之作

定义了CNN的基本组件, 是CNN的鼻祖

<a name="LeNet基本架构"></a>

### 基本架构

卷积层、池化层、全连接层

<a name="LeNet-5模型"></a>

### LeNet-5模型

1. 输入的图像是28*28像素的图像, 用矩阵表示为[1, 28, 28]
2. 第一个卷积层所用的卷积核为5 * 5, 滑动步长为1, 卷积核数目为20; 经过该层后图像尺寸变为(28-5+1=24), 输出矩阵为[20, 24, 24]
3. 第一个池化层pool核尺寸为2*2, 步长为2, 池化操作后, 图像尺寸减半, 输出矩阵为[20, 12, 12]
4. 第一个卷积层所用的卷积核为5 * 5, 滑动步长为1, 卷积核数目为50; 经过该层后图像尺寸变为(12-5+1=8), 输出矩阵为[50, 8, 8]
5. 第二个池化层pool核尺寸为2*2, 步长为2, 池化操作后, 图像尺寸减半, 输出矩阵为[50, 4, 4]
6. 第一个全连接层, 神经元数目为500, 再接`relu`激活函数
7. 第二个全连接层, 神经元个数为10, 用于10个数字的训练, 再接`softmax`函数, 最终得到分类的概率

![LeNet-5](https://images2017.cnblogs.com/blog/1093303/201802/1093303-20180217131630609-291700181.png)

<a name="LeNet的Keras实现"></a>

### LeNet的Keras实现

```python
def LeNet():
    model = Sequential()
    model.add(Conv2D(32,(5,5),strides=(1,1),input_shape=(28,28,1),padding='valid',activation='relu',kernel_initializer='uniform'))
    model.add(MaxPooling2D(pool_size=(2,2)))
    model.add(Conv2D(64,(5,5),strides=(1,1),padding='valid',activation='relu',kernel_initializer='uniform'))
    model.add(MaxPooling2D(pool_size=(2,2)))
    model.add(Flatten())
    model.add(Dense(100,activation='relu'))
    model.add(Dense(10,activation='softmax'))
    return model
```

------

<a name="AlexNet"></a>

## AlexNet -> 王者归来

<a name="AlexNet优势"></a>

### 优势

- 更深的网络
- 数据增广来增加模型的泛化能力
- 用ReLU代替Sigmoid来加快SGD的收敛速度
- Dropout防止模型过拟合
- LRN

<a name="AlexNet模型></a>

### AlexNet模型

1. 前面5层是卷积层, 后面三层是全连接层, 最终`softmax`输出是1000类

2. 输入图片为256*256的三通道彩色照片, 为了增强模型的泛化能力, 避免过拟合, 使用随机裁剪得到3\*224\*224的图像, 作为网络的输入

   ![随机裁剪](https://images2017.cnblogs.com/blog/1093303/201802/1093303-20180217131703406-1977094290.png)

3. 使用GPU再第一层卷积层后有两个完全一样的分支加速训练

![AlexNet](https://images2017.cnblogs.com/blog/1093303/201802/1093303-20180217131643890-1883639712.png)

<a name="AlexNet的Keras实现"></a>

### AlexNet的Keras实现

```python
def AlexNet():
    model = Sequential()
    model.add(Conv2D(96,(11,11),strides=(4,4),input_shape=(227,227,3),padding='valid',activation='relu',kernel_initializer='uniform'))
    model.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))
    model.add(Conv2D(256,(5,5),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))
    model.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))
    model.add(Conv2D(384,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))
    model.add(Conv2D(384,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))
    model.add(Conv2D(256,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))
    model.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))
    model.add(Flatten())
    model.add(Dense(4096,activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(4096,activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(1000,activation='softmax'))
    return model
```

------

<a name="Googlenet"></a>

## Googlenet -> 大浪推手

在加深网络的同时, 引入Inception结构代替了单纯的卷积激活的传统操作

<a name="Googlenet优势"></a>

### 优势

- 引入Inception结构
- 中间层的辅助LOSS单元
- 后面的全连接层全部替换为简单的全局平均pooling

<a name="Inception模型"></a>

### Inception模型

1. 卷积stride都是1
2. 为了保持特征相应图大小一致, 都用0填充
3. 每个卷积层后面都立即接一个`relu`函数, 并把4组不同类型但大小相同的特征相应图一张张并排叠起来, 形成新的特征相应图
4. **主要功能:**
   - 通过3*3的池化, 以及1\*1、3\*3、5\*5三种不同尺度的卷积核, 一共4中方式对输入的特征相应图做了特征提取
   - 采用1*1卷积核实现降维, 同时让信息通过更少的连接传递以达到更加稀疏的特性
5. 网络结构中有3个LOSS单元, 这样做是为了帮助网络的收敛: 在中间层加入腐竹计算的LOSS单元, 使得计算损失时让低层的特征有很好的区分能力, 从而让网络更好的被训练
6. 后面的全连接层全部替换为简单的全局平均pooling

![Inception](https://images2017.cnblogs.com/blog/1093303/201802/1093303-20180217131828906-234829229.png)

<a name="GoogLeNet的Keras实现"></a>

### GoogLeNet的Keras实现

```python
def Conv2d_BN(x, nb_filter,kernel_size, padding='same',strides=(1,1),name=None):
    if name is not None:
        bn_name = name + '_bn'
        conv_name = name + '_conv'
    else:
        bn_name = None
        conv_name = None

    x = Conv2D(nb_filter,kernel_size,padding=padding,strides=strides,activation='relu',name=conv_name)(x)
    x = BatchNormalization(axis=3,name=bn_name)(x)
    return x

def Inception(x,nb_filter):
    branch1x1 = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),name=None)

    branch3x3 = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),name=None)
    branch3x3 = Conv2d_BN(branch3x3,nb_filter,(3,3), padding='same',strides=(1,1),name=None)

    branch5x5 = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),name=None)
    branch5x5 = Conv2d_BN(branch5x5,nb_filter,(1,1), padding='same',strides=(1,1),name=None)

    branchpool = MaxPooling2D(pool_size=(3,3),strides=(1,1),padding='same')(x)
    branchpool = Conv2d_BN(branchpool,nb_filter,(1,1),padding='same',strides=(1,1),name=None)

    x = concatenate([branch1x1,branch3x3,branch5x5,branchpool],axis=3)

    return x

def GoogLeNet():
    inpt = Input(shape=(224,224,3))
    #padding = 'same'，填充为(步长-1）/2,还可以用ZeroPadding2D((3,3))
    x = Conv2d_BN(inpt,64,(7,7),strides=(2,2),padding='same')
    x = MaxPooling2D(pool_size=(3,3),strides=(2,2),padding='same')(x)
    x = Conv2d_BN(x,192,(3,3),strides=(1,1),padding='same')
    x = MaxPooling2D(pool_size=(3,3),strides=(2,2),padding='same')(x)
    x = Inception(x,64)#256
    x = Inception(x,120)#480
    x = MaxPooling2D(pool_size=(3,3),strides=(2,2),padding='same')(x)
    x = Inception(x,128)#512
    x = Inception(x,128)
    x = Inception(x,128)
    x = Inception(x,132)#528
    x = Inception(x,208)#832
    x = MaxPooling2D(pool_size=(3,3),strides=(2,2),padding='same')(x)
    x = Inception(x,208)
    x = Inception(x,256)#1024
    x = AveragePooling2D(pool_size=(7,7),strides=(7,7),padding='same')(x)
    x = Dropout(0.4)(x)
    x = Dense(1000,activation='relu')(x)
    x = Dense(1000,activation='softmax')(x)
    model = Model(inpt,x,name='inception')
    return model
```

------

<a name="VGG"></a>

## VGG -> 越走越深

<a name="VGG简介"></a>

### 简介

为了解决初始化等问题, VGG采用pre-training的方式: 先训练一部分小网络, 在确保这部分网络稳定之后, 再在此基础上逐渐加深

<a name="VGG-16网络结构"></a>

### VGG-16网络结构

1. 卷积层都是相同的卷积, 因此卷积过后输出图像的尺寸与输入是一只的
2. 下采样完全是有max pooling实现的
3. VGG网络后接三个全连接层, filter(卷积后的输出通道数)个数从64开始, 每接一个pooling后成倍增加
4. 卷积层使用更小的filter尺寸和间隔
   - 多个3*3的卷积层比一个大尺寸filter卷积层有更多的非线性, 是的判决函数更加具有判决行
   - 多个3*3的卷积层比一个大尺寸filter卷积层油更少的参数
   - 1*1卷积核课在不影响输入输出维数的情况下, 对输入进行线性形变, 然后通过`relu`进行非线性处理, 增加网络的非线性表达能力

![VGG-16](https://images2017.cnblogs.com/blog/1093303/201802/1093303-20180217131751843-269987601.png)

<a name="VGG-16的Keras实现"></a>

### VGG-16的Keras实现

```python
def VGG_16():   
    model = Sequential()
    
    model.add(Conv2D(64,(3,3),strides=(1,1),input_shape=(224,224,3),padding='same',activation='relu',kernel_initializer='uniform'))
    model.add(Conv2D(64,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))
    model.add(MaxPooling2D(pool_size=(2,2)))
    
    model.add(Conv2D(128,(3,2),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))
    model.add(Conv2D(128,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))
    model.add(MaxPooling2D(pool_size=(2,2)))
    
    model.add(Conv2D(256,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))
    model.add(Conv2D(256,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))
    model.add(Conv2D(256,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))
    model.add(MaxPooling2D(pool_size=(2,2)))
    
    model.add(Conv2D(512,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))
    model.add(Conv2D(512,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))
    model.add(Conv2D(512,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))
    model.add(MaxPooling2D(pool_size=(2,2)))
    
    model.add(Conv2D(512,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))
    model.add(Conv2D(512,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))
    model.add(Conv2D(512,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))
    model.add(MaxPooling2D(pool_size=(2,2)))
    
    model.add(Flatten())
    model.add(Dense(4096,activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(4096,activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(1000,activation='softmax'))
    
    return model
```

------

<a name="Resent"></a>

## Resent -> 里程碑式的创新

<a name="Resent优势"></a>

### 优势

- 层数非常深, 已经超过百层
- 引入残差单元来解决退化问题

<a name="残差单元"></a>

### 残差单元

![残差](https://images2017.cnblogs.com/blog/1093303/201802/1093303-20180217131941296-1327847371.png)

1. 数据经过了两条路线，一条是常规路线，另一条则是捷径（shortcut），直接实现单位映射的直接连接的路线，类似与电路中的“短路”

2. 把网络中的一个模块的输入和输出关系看作是y=H(x)，那么直接通过梯度方法求H(x)就会遇到退化问题，如果使用带shortcut的结构，那么可变参数部分的优化目标就不再是H(x), 若用F(x)来代表需要优化的部分的话，则`H(x)=F(x)+x`，也就是`F(x)=H(x)-x`

3. 在单位映射的假设中`y=x`就相当于观测值，所以F(x)就对应着残差，因而叫残差网络

4. 考虑到x的维度与F(X)维度可能不匹配情况，需进行维度匹配

   - zero_padding:对恒等层进行0填充的方式将维度补充完整, 不会增加额外的参数
   - projection:在恒等层采用1x1的卷积核来增加维度, 会增加额外的参数

5. **残差模块:**

   - 常规残差模块，有两个3×3卷积核卷积核组成，但是随着网络进一步加深，这种残差结构在实践中并不是十分有效
   - “瓶颈残差模块”可以有更好的效果，它依次由1×1、3×3、1×1这三个卷积层堆积而成，这里的1×1的卷积能够起降维或升维的作用，从而令3×3的卷积可以在相对较低维度的输入上进行，以达到提高计算效率的目的。

   ![残差模块](https://images2017.cnblogs.com/blog/1093303/201802/1093303-20180217132002999-1852938927.png)

<a name="ResNet-50的Keras实现"></a>

### ResNet-50的Keras实现

```python
def Conv2d_BN(x, nb_filter,kernel_size, strides=(1,1), padding='same',name=None):
    if name is not None:
        bn_name = name + '_bn'
        conv_name = name + '_conv'
    else:
        bn_name = None
        conv_name = None

    x = Conv2D(nb_filter,kernel_size,padding=padding,strides=strides,activation='relu',name=conv_name)(x)
    x = BatchNormalization(axis=3,name=bn_name)(x)
    return x

def Conv_Block(inpt,nb_filter,kernel_size,strides=(1,1), with_conv_shortcut=False):
    x = Conv2d_BN(inpt,nb_filter=nb_filter[0],kernel_size=(1,1),strides=strides,padding='same')
    x = Conv2d_BN(x, nb_filter=nb_filter[1], kernel_size=(3,3), padding='same')
    x = Conv2d_BN(x, nb_filter=nb_filter[2], kernel_size=(1,1), padding='same')
    if with_conv_shortcut:
        shortcut = Conv2d_BN(inpt,nb_filter=nb_filter[2],strides=strides,kernel_size=kernel_size)
        x = add([x,shortcut])
        return x
    else:
        x = add([x,inpt])
        return x

def ResNet50():
    inpt = Input(shape=(224,224,3))
    x = ZeroPadding2D((3,3))(inpt)
    x = Conv2d_BN(x,nb_filter=64,kernel_size=(7,7),strides=(2,2),padding='valid')
    x = MaxPooling2D(pool_size=(3,3),strides=(2,2),padding='same')(x)
    
    x = Conv_Block(x,nb_filter=[64,64,256],kernel_size=(3,3),strides=(1,1),with_conv_shortcut=True)
    x = Conv_Block(x,nb_filter=[64,64,256],kernel_size=(3,3))
    x = Conv_Block(x,nb_filter=[64,64,256],kernel_size=(3,3))
    
    x = Conv_Block(x,nb_filter=[128,128,512],kernel_size=(3,3),strides=(2,2),with_conv_shortcut=True)
    x = Conv_Block(x,nb_filter=[128,128,512],kernel_size=(3,3))
    x = Conv_Block(x,nb_filter=[128,128,512],kernel_size=(3,3))
    x = Conv_Block(x,nb_filter=[128,128,512],kernel_size=(3,3))
    
    x = Conv_Block(x,nb_filter=[256,256,1024],kernel_size=(3,3),strides=(2,2),with_conv_shortcut=True)
    x = Conv_Block(x,nb_filter=[256,256,1024],kernel_size=(3,3))
    x = Conv_Block(x,nb_filter=[256,256,1024],kernel_size=(3,3))
    x = Conv_Block(x,nb_filter=[256,256,1024],kernel_size=(3,3))
    x = Conv_Block(x,nb_filter=[256,256,1024],kernel_size=(3,3))
    x = Conv_Block(x,nb_filter=[256,256,1024],kernel_size=(3,3))
    
    x = Conv_Block(x,nb_filter=[512,512,2048],kernel_size=(3,3),strides=(2,2),with_conv_shortcut=True)
    x = Conv_Block(x,nb_filter=[512,512,2048],kernel_size=(3,3))
    x = Conv_Block(x,nb_filter=[512,512,2048],kernel_size=(3,3))
    x = AveragePooling2D(pool_size=(7,7))(x)
    x = Flatten()(x)
    x = Dense(1000,activation='softmax')(x)
    
    model = Model(inputs=inpt,outputs=x)
    return model
```
