# *ilab*医学影像暑期科研

2019-07-23 张喆学习笔记


Table of Contents
=================

   * [<em>ilab</em>医学影像暑期科研](#ilab医学影像暑期科研)
   * [第一门课 神经网路和深度学习](#第一门课-神经网路和深度学习)
      * [第二周: 神经网络的编程基础](#第二周-神经网络的编程基础)
         * [向量化](#向量化)
            * [向量化的例子](#向量化的例子)
         * [向量化的逻辑回归](#向量化的逻辑回归)
            * [前向传播的向量化](#前向传播的向量化)
            * [梯度下降的向量化](#梯度下降的向量化)
            * [逻辑回归的向量化](#逻辑回归的向量化)
         * [广播](#广播)
         * [python - numpy向量](#python---numpy向量)
            * [广播的优缺点](#广播的优缺点)
            * [一维数组与向量的不同点](#一维数组与向量的不同点)

# 第一门课 神经网路和深度学习

## 第二周: 神经网络的编程基础

### 向量化

#### 向量化的例子

例1. 计算$z=w^{T} x+b$

```python
import numpy as np

# 暴力循环法
def forloop(w,x,b):
    z = 0
    for i in range(len(x)):
        z += w[i]*x[i]
    z += b

# 向量法
def vector(w,x,b):
    z = np.dot(w,x) + b

if __name__ == "__main__":
    w = [w for w in range(1,1000)]
    x = [x for x in range(1000,1,-1)]
    b = 100

    forloop(w,x,b)
    vector(w,x,b)
```

> 但实际测试过后, 将每种算法执行5000次, 运行结果如下:
>
> Time forloop: 5.08
> Time vector: 7.18

但是如果将产生数组的方式更换为

```python
w = np.random.rand(1000000)
x = np.random.rand(1000000)
```

向量化的版本运行效率显著提升, 效率提升了大致300倍

> Time forloop: 3.23 
> Time vector: 0.01

例2. u = Av, u,v均为向量, A为矩阵, 例A的维度为2\*3, v为3\*1, 结果u为2*1

```python
import numpy as np

def vector():
    A = np.array([[1,2,3],[4,5,6]])
    v = np.array([[4],[5],[6]])
    u = np.zeros((2,1))

    u = np.dot(A,v)
    print(u)
    
def forloop():
    A = [
        [1,2,3],
        [4,5,6],
    ]

    v = [
        [4],
        [5],
        [6],
    ]

    u = [
        [0],
        [0],
    ]

    for i in range(len(A)):
        for j in range(len(A[i])):
            print(A[i][j])
            print(v[j][0])
            u[i][0] += A[i][j] * v[j][0]
    print(u)
```

例3. 有一个向量v, 想对v的每个元素做指数运算

```python
u = np.exp(v)
```

`numpy`库中还有很多向量函数`np.log()`, `np.abs()`......

### 向量化的逻辑回归

#### 前向传播的向量化

Z = np.dot(w.T, X) + b

b是一个实数(1\*1的矩阵), 但是当向量加上一个实数时, python会自动把这个实数扩展成一个1\*m的行向量

#### 梯度下降的向量化

dw = 1/m * X * dz.T

db = 1/m * np.sum(dZ)

#### 逻辑回归的向量化

**循环方法**

```python
J,dw1,dw2,db = 0,0,0,0
for i in range(0,m):
    z[i] = w*x[i] + b
    a[i] = sigmoid(z[i])
    J += -(y[i]*log(a[i]) + (1-y[i])*log(1-a[i]))
    dz[i] = a[i] - y[i]
    dw1 += x1[i] * dz[i]
    dw2 += x2[i] * dz[i]
    db += dz[i]
J /= m
dw1 /= m
dw2 /= m
db /=m

w -= alpha * dw
b -= alpha * db
```

**使用向量表示**

```python
# 对训练样本进行预测和求导
Z = np.dot(w.T, X) + b
A = 𝜎(Z)
dZ = A - Y
dw = 1/m * X * dz.T
db = 1/m * np.sum(dZ)
# 梯度下降更新参数
w -= alpha * dw
b -= alpha * db
```

### 广播

例. 计算不同食物中不同营养恒分中的卡了压力百分比

![image.png](https://upload-images.jianshu.io/upload_images/12014150-406e19a5bc2da39e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

```python
import numpy as np

A = np.array([[56.0, 0.0, 4.4, 68.0],
              [1.2, 104.0, 52.0, 8.0],
              [1.8, 135.0, 99.0, 0.9]])

cal = A.sum(axis = 0)   # 0为按列计算, 1为按行计算

percentage = A / cal.reshape(1,4)
print(percentage)
```

- 比如计算苹果中卡路里所占的百分比, 先计算56.0+1.2+1.8 = 59; 56/59 = 0.949
- 计算百分比时: 将3\*4的矩阵A初一一个1\*4的矩阵, 得到了一个3\*4的结果矩阵, 即为所求
- 理论上`cal`本身是一个1\*4的向量, 不需要再进行reshape, 但是当我们写代码不确定矩阵维度的时候, 可以对矩阵进行重塑来确保得到我们想要的矩阵, 而reshape的时间复杂度是`O(1)`, 调用代价极低

**广播机制**

- 一个4\*1的列向量与一个常数做加法时, 会将常数扩展为一个4*1的列向量, 然后再按照矩阵的加法进行

- 广播机制对与列向量和行向量均可以使用

  ![image.png](https://upload-images.jianshu.io/upload_images/12014150-b216b1a925fd3e2c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

  ![image.png](https://upload-images.jianshu.io/upload_images/12014150-0822a8eeeb6eca86.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

  ![image.png](https://upload-images.jianshu.io/upload_images/12014150-ee82d278d570e114.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

- 后缘维度的轴长度: `A.shape[-1]`, 即列数;   

  **<u>如果两个数组的后院维度的轴长度相符或其中一方的轴长度为1, 则认为他们是广播兼容的, 广播会在缺失维度和轴长度为1的维度上进行</u>***

  卡路里的例子中A<sub>3*4</sub>的后缘维度的轴长度等于4; 而cal<sub>1*4</sub>的后缘维度也是4, 二者的后缘维度轴长度相符, 因此可以进行广播

  广播会在轴长度为1的维度对应`axis=0`即垂直方向, 复制成cal_temp<sub>3*4</sub>, 之后二者再进行运算

### python - numpy向量

#### 广播的优缺点

- 巨大的灵活性

- 不熟悉的话可能有奇怪的bug

  比如一个n维列向量加上一个n维行向量, 不会报维度不匹配或类型错误之类的错误, 而是得到了广播后的结果

```python
import numpy as np

A = np.array([1,2,3])
B = np.array([[1],[2],[3]])
result = A + B
print(result)
'''
Output:
[[2 3 4]
 [3 4 5]
 [4 5 6]]
'''
```

#### 一维数组与向量的不同点

一维数组    ❗❗❗**(在神经网络中不要使用)**

- 它不是行向量也不是列向量
- 转置后跟它本身看起来一样
- a乘以a的转置返回的是内积 --> 一个数

```python
import numpy as np

a = np.random.randn(5)
print(a)    # [-1.225  0.282 -0.958  1.176 -0.707]
print(a.shape)  # (5,)
print(a.T)  # [-1.225  0.282 -0.958  1.176 -0.707]
print(np.dot(a, a.T))   # 4.385
```

列向量

- 我们设置它的shape为(5,1)
- 这样输出它的转置时有两个[[ ]], 它变成一个行向量了
- 二者的乘积返回的是外积 --> 一个矩阵

```python
import numpy as np

a = np.random.randn(5,1)
print(a)    '''
            [[ 0.03078465]
            [ 0.52937981]
            [-1.29145158]
            [-0.3743261 ]
            [ 0.46156606]]
            '''
print(a.shape)  # (5,1)
print(a.T)  # [[ 0.03078465  0.52937981 -1.29145158 -0.3743261   0.46156606]]
print(np.dot(a, a.T))   '''
                        [[ 9.47694739e-04  1.62967726e-02 -3.97568863e-02 -1.15234983e-02 1.42091501e-02]
                        [ 1.62967726e-02  2.80242978e-01 -6.83668388e-01 -1.98160677e-01 2.44343752e-01]
                        [-3.97568863e-02 -6.83668388e-01  1.66784719e+00  4.83424032e-01 -5.96090221e-01]
                        [-1.15234983e-02 -1.98160677e-01  4.83424032e-01  1.40120028e-01 -1.72776223e-01]
                        [ 1.42091501e-02  2.44343752e-01 -5.96090221e-01 -1.72776223e-01 2.13043229e-01]]
                        '''
```

如果不确定行/列向量是否shape有第二个维度(不是一维数组), 可以加入断言`assert(a.shape == (5,1))`, 或者reshape `a = np.random.randn(5).reshape(5,1)`
