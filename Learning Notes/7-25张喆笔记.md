# *ilab*医学影像暑期科研

2019-07-25 张喆学习笔记

Table of Contents
=================

   * [<em>ilab</em>医学影像暑期科研](#ilab医学影像暑期科研)
   * [第一门课 神经网路和深度学习](#第一门课-神经网路和深度学习)
      * [第三周: 浅层神经网络](#第三周-浅层神经网络)
         * [神经网络的表示](#神经网络的表示)
         * [计算神经网络的输出](#计算神经网络的输出)

# 第一门课 神经网路和深度学习

## 第三周: 浅层神经网络

### 神经网络的表示

![image.png](https://upload-images.jianshu.io/upload_images/12014150-835027da125225f7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

- 输入层
- 隐藏层： 在训练集中不知道它们的准确值
- 输出层： 产生预测值

- 激活值：a<sup>[i]</sup>表示输入特征 （a是激活的意思，意味着网络中不同层的值回传递到后面的层中）
  - 输入层的激活值为a<sup>[0]</sup>
  - 隐藏层的第一个结点的激活值记为a<sub>1</sub><sup>[0]</sup>，所以a<sup>[1]</sup>是一个大小为4的列向量
  - 输出层的激活值a<sup>[2]</sup>即为我们要的$\hat{y}$
- x表示输入特征
- a表示每个神经元的输出
- W表示特征的权重；上标表示神经网络的层数，下表表示该层的第几个神经元

说明：

- 这是一个两层的神经网络（通常输入层不算入其中）
- 隐藏层和输出层是带有参数的
  - 隐藏层有参数W<sup>[1]</sup>和b<sup>[1]</sup>，W是一个4*3的矩阵，b是一个4\*1的向量；4是隐藏层单元的结点数，3是因为有三个输入特征
  - 输出层有与之关联的W<sup>[2]</sup>和b<sup>[2]</sup>，大小分别为1\*4和1*1；该层有1个结点，上一层有4个结点

### 计算神经网络的输出

1. 按步骤计算出z
2. 以sigmoid函数为激活函数计算z(得出a)
3. 重复这个过程

**两层的神经网络:**

1. 计算$z_{1}^{[1]}, z_{1}^{[1]}=w_{1}^{[1] T} x+b_{1}^{[1]}$
2. 通过激活函数计算$a_{1}^{[1]}, a_{1}^{[1]}=\sigma\left(z_{1}^{[1]}\right)$
3. 重复这个过程, 分别计算$a_{2}^{[1]}, a_{3}^{[1]}, a_{4}^{[1]}$

**向量化计算:** 

将神经网络中的一层神经元参数纵向堆积起来

例如隐藏层中的w纵向堆积起来变成4\*3的矩阵, 用W<sup>[1]</sup>表示

$z^{[n]}=w^{[n] } x+b^{[n]}$, $a^{[n]}=\sigma\left(z^{[n]}\right)$

在这个两层的神经网络中, 输入x可以表示为$a^{[0]}$, 最终的输出为$\hat{y}=a^{[2]}$

**最终的计算过程:** 

![image.png](https://upload-images.jianshu.io/upload_images/12014150-1b588e542e7119c4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
