





# MINST手写数字识别

[TOC]

## minst数据集

**该数据集包含以下四个部分**

- train-images-idx3-ubyte.gz: 训练集-图片，6w
- train-labels-idx1-ubyte.gz: 训练集-标签，6w
- t10k-images-idx3-ubyte.gz: 测试集-图片，1w
- t10k-labels-idx1-ubyte.gz: 测试集-标签，1w

### 图片

每张图片大小为28*28像素, 可以用28\*28大小的数组来表示一张图片

### 标签

用大小为10的数组来表示

### one-hot编码(独热编码)

使用N位表示N种状态, 任何时候只有其中的一位有效

> 例如
>
> 性别:  
> [0, 1]代表女，[1, 0]代表男
>
> 数字0-9: 
> [0,0,0,0,0,0,0,0,0,1]代表9，[0,1,0,0,0,0,0,0,0,0]代表1

**优点:**

- 能够处理非连续性数值特征
- 一定程度上扩充了特征(性别本身是一个特征, 经过编码以后, 就变成了男或女两个特征)
- 容错性: 比如神经网络的输出结果是 [0,0.1,0.2,0.7,0,0,0,0,0, 0]转成独热编码后，表示数字3。即值最大的地方变为1，其余均为0。[0,0.1,0.4,0.5,0,0,0,0,0, 0]也能表示数字3。

## 神经网络

### 输入/输出/标签

- 输入: 传入给网络处理的向量, *784(28*28)的向量*
- 输出: 网络处理后返回的结果: *大小为10的概率向量*
- 标签: 期望网络返回的结果

### 损失函数 -> 交叉熵

**作用**: 评估网络模型的好坏

**目标:** 传入大量的训练集训练目标, 将损失函数的值降到最小

 **函数形式:** `-sum(label * log(y))`

**优点**: 只关注独热编码中有效位的损失, 屏蔽了无效位的变化(不会影响最终的结果), 并且通过取对数放大了有效位的损失

> 例: [0, 0, 1] 与 [0.1, 0.3, 0.6]的交叉熵为 -log(0.6) = 0.51[0, 0, 1] 与 [0.2, 0.2, 0.6]的交叉熵为 -log(0.6) = 0.51[0, 0, 1] 与 [0.1, 0, 0.9]的交叉熵为 -log(0.9) = 0.10

![image.png](https://upload-images.jianshu.io/upload_images/12014150-2f418be5d976cf21.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

### 回归模型

**作用**: 如果把网络理解为一个函数, 回归模型是希望对这个函数进行拟合

**方法**: 不断地传入X和label的值, 来修正w和b, 使得最终得到的Y和label的loss最小

可以采用梯度下降法, 找到最快的方向, 调整w和b的值, 使得w*X + b的值越来越接近label

### 学习速率

![image.png](https://upload-images.jianshu.io/upload_images/12014150-02bf061551a313c8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

### 激活函数 -> softmax

再计算交叉熵前的Y值是经过softmax后的，经过softmax后的Y，并不影响Y向量的每个位置的值之间的大小关系。大致有2个作用，一是放大效果，二是梯度下降时需要一个可导的函数。

softmax函数将任意n维的实值向量转换为取值范围在(0,1)之间的n维实值向量，并且总和为1。

> 例如：向量softmax([1.0, 2.0, 3.0]) ------> [0.09003057, 0.24472847, 0.66524096]

**性质：**

1. 因为softmax是单调递增函数，因此不改变原始数据的大小顺序。
2. 将原始输入映射到(0,1)区间，并且总和为1，常用于表征概率。
3. softmax(x) = softmax(x+c), 这个性质用于保证数值的稳定性。

```python
def softmax(x):
    import numpy as np
    return np.exp(x) / np.sum(np.exp(x), axis=0)

softmax([4, 5, 10])
# [ 0.002,  0.007,  0.991]
```



在第一个tuple训练完后，我们可以把第二个tuple利用神经网络进行分类，根据实验结果的真实值与我们的预测值进行对比得到相应的损失值，再利用反向传播进行参数更新，再进行分类，然后重复前述步骤直至损失值最小

![image-20190730201714778.png](https://upload-images.jianshu.io/upload_images/12014150-ee5e97fff8729f60.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)


![image-20190731194915115.png](https://upload-images.jianshu.io/upload_images/12014150-3f302abe4e10ffdc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

